#!/usr/bin/env python3

import argparse
import sqlite3
from pathlib import Path
from typing import List, Sequence, Tuple


NON_ID_COLUMNS: Sequence[str] = (
    "study_id",
    "study_label",
    "dataset_id",
    "molecular_trait_id",
    "gene_id",
    "gene_name",
    "variant",
    "rsid",
    "quantification_method",
    "credible_set",
    "credible_set_size",
    "pip",
    "pvalue",
    "beta",
    "se",
    "dataset_label",
    "plot_variant",
)


def log_step(message: str) -> None:
    print(f"[audit] {message}", flush=True)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Audit row-level deduplication using script1 list and script2 output."
    )
    parser.add_argument(
        "--input-list",
        required=True,
        help="Text file with one absolute SQLite path per line (script 1 output).",
    )
    parser.add_argument(
        "--merged-sqlite",
        required=True,
        help="Merged SQLite file generated by script 2.",
    )
    parser.add_argument(
        "--report-file",
        required=False,
        default=None,
        help="Optional report file path.",
    )
    return parser.parse_args()


def read_sqlite_paths(list_file: Path) -> List[Path]:
    if not list_file.exists():
        raise ValueError(f"Input list file does not exist: {list_file}")

    paths: List[Path] = []
    with list_file.open("r", encoding="utf-8") as handle:
        for raw_line in handle:
            line = raw_line.strip()
            if not line:
                continue
            path = Path(line).resolve()
            if not path.is_absolute():
                raise ValueError(f"Expected absolute path in input list, got: {line}")
            if not path.exists():
                raise ValueError(f"Input SQLite file does not exist: {path}")
            paths.append(path)

    if not paths:
        raise ValueError(f"Input list file has no SQLite paths: {list_file}")
    return paths


def distinct_row_count(conn: sqlite3.Connection, table_ref: str) -> int:
    columns = ", ".join(NON_ID_COLUMNS)
    query = f"SELECT COUNT(*) FROM (SELECT DISTINCT {columns} FROM {table_ref});"
    return conn.execute(query).fetchone()[0]


def process_input_sources(
    conn: sqlite3.Connection,
    input_paths: Sequence[Path],
) -> List[Tuple[Path, int, int]]:
    per_file_counts: List[Tuple[Path, int, int]] = []
    total = len(input_paths)
    for source_order, source_path in enumerate(input_paths):
        log_step(f"Step 3/5 - Processing input {source_order + 1}/{total}: {source_path}")
        alias = f"src_{source_order}"
        conn.execute(f"ATTACH DATABASE ? AS {alias};", (str(source_path),))
        try:
            row_count = conn.execute(f"SELECT COUNT(*) FROM {alias}.credible_set_table;").fetchone()[0]
            log_step(
                f"Step 3/5 - Counting distinct rows for input {source_order + 1}/{total}"
            )
            distinct_rows = distinct_row_count(conn, f"{alias}.credible_set_table")
            per_file_counts.append((source_path, int(row_count), int(distinct_rows)))
            log_step(
                f"Step 3/5 - Finished input {source_order + 1}/{total}: "
                f"rows={row_count}, distinct={distinct_rows}"
            )
        finally:
            conn.execute(f"DETACH DATABASE {alias};")
    return per_file_counts


def build_report(
    conn: sqlite3.Connection,
    per_file_counts: Sequence[Tuple[Path, int, int]],
    merged_sqlite: Path,
) -> str:
    total_input_rows = sum(count for _, count, _ in per_file_counts)
    total_input_distinct_per_file = sum(distinct for _, _, distinct in per_file_counts)
    merged_rows = conn.execute("SELECT COUNT(*) FROM merged.credible_set_table;").fetchone()[0]
    merged_distinct_rows = distinct_row_count(conn, "merged.credible_set_table")
    duplicate_rows_removed = total_input_rows - merged_rows
    within_source_duplicate_rows = total_input_rows - total_input_distinct_per_file

    lines: List[str] = []
    lines.append("Merge audit report")
    lines.append(f"Merged SQLite: {merged_sqlite}")
    lines.append("")
    lines.append("Per-input row counts (raw vs distinct by non-id columns):")
    for source_path, count, distinct in per_file_counts:
        lines.append(
            f"- {source_path}\trows={count}\tdistinct={distinct}\tduplicates={count - distinct}"
        )
    lines.append("")
    lines.append(f"Total input rows: {total_input_rows}")
    lines.append(f"Merged rows: {merged_rows}")
    lines.append(f"Merged distinct rows (non-id columns): {merged_distinct_rows}")
    lines.append(f"Duplicate rows removed: {duplicate_rows_removed}")
    lines.append(f"Within-source duplicate rows (sum across files): {within_source_duplicate_rows}")
    lines.append("")
    lines.append("Merged-output integrity checks:")
    lines.append(
        f"- Dedup check (merged rows == merged distinct rows): {merged_rows == merged_distinct_rows}"
    )
    return "\n".join(lines)


def main() -> None:
    log_step("Step 1/5 - Parsing arguments")
    args = parse_args()
    input_list = Path(args.input_list).resolve()
    merged_sqlite = Path(args.merged_sqlite).resolve()
    report_file = Path(args.report_file).resolve() if args.report_file else None

    log_step("Step 2/5 - Validating input paths")
    if not merged_sqlite.exists():
        raise ValueError(f"Merged SQLite does not exist: {merged_sqlite}")

    input_paths = read_sqlite_paths(input_list)
    log_step(f"Step 2/5 - Found {len(input_paths)} input SQLite files")

    log_step("Step 3/5 - Starting per-input audits")
    conn = sqlite3.connect(":memory:")
    try:
        log_step("Step 4/5 - Attaching merged SQLite and computing final report metrics")
        conn.execute("ATTACH DATABASE ? AS merged;", (str(merged_sqlite),))
        per_file_counts = process_input_sources(conn, input_paths)
        report = build_report(conn, per_file_counts, merged_sqlite)
    finally:
        conn.close()

    log_step("Step 5/5 - Printing and writing report")
    print(report)
    if report_file:
        report_file.parent.mkdir(parents=True, exist_ok=True)
        report_file.write_text(report + "\n", encoding="utf-8")
        print(f"\nWrote report file: {report_file}")
    log_step("Completed")


if __name__ == "__main__":
    main()
